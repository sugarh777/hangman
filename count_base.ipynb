{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "count_base.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOU0LPAUYi+k3colRxr+GZy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugarh777/hangman/blob/master/count_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUWgj69eRu-D",
        "colab_type": "code",
        "outputId": "24c2f616-8cf7-46a4-9bb1-6df8d75b50b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90m-0hzk4hvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import sys, os, pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from sklearn.utils.extmath import randomized_svd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUoRefggjnyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process(text):\n",
        "  txt = text.lower()\n",
        "  txt = txt.replace('.',' .')\n",
        "  words = txt.split(' ')\n",
        "\n",
        "  word_to_id = {}\n",
        "  id_to_word = {}\n",
        "\n",
        "  for word in words:\n",
        "    if word not in word_to_id:\n",
        "      new_id = len(word_to_id)\n",
        "      word_to_id[word] = new_id\n",
        "      id_to_word[new_id] = word\n",
        "\n",
        "  corpus = np.array([word_to_id[w] for w in words])\n",
        "\n",
        "  return corpus, word_to_id, id_to_word\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiMwpKsXnXxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_co_matrix(corpus,vocab_size,window_size=1):\n",
        "  corpus_size = len(corpus)\n",
        "  co_matrix = np.zeros((vocab_size,vocab_size),dtype=np.int32)\n",
        "\n",
        "  for idx, word_id in enumerate(corpus):\n",
        "    for i in range(1,window_size+1):\n",
        "      left_idx = idx - i\n",
        "      right_idx = idx + i\n",
        "\n",
        "      if left_idx >= 0:\n",
        "        left_word_id = corpus[left_idx]\n",
        "        co_matrix[word_id,left_word_id] += 1\n",
        "\n",
        "      if right_idx < corpus_size:\n",
        "        right_word_id = corpus[right_idx]\n",
        "        co_matrix[word_id,right_word_id] += 1\n",
        "\n",
        "  return co_matrix\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gelZGitNlaEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cos_similarity(x,y,eps=1e-8):\n",
        "\n",
        "  nx = x / np.sqrt(np.sum(x**2) + eps)\n",
        "  ny = y / np.sqrt(np.sum(y**2) + eps)\n",
        "\n",
        "  return np.dot(nx,ny)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37kiUYJcnPwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def most_similar(query,word_to_id,id_to_word,word_matrix,top=5):\n",
        "  if query not in word_to_id:\n",
        "    print('{} is not found.'.format(query))\n",
        "    return\n",
        "\n",
        "  print('\\n[query] {}'.format(query))\n",
        "  query_id = word_to_id[query]\n",
        "  query_vec = word_matrix[query_id]\n",
        "\n",
        "  vocab_size = len(id_to_word)\n",
        "  similarity = np.zeros(vocab_size)\n",
        "  \n",
        "  for i in range(vocab_size):\n",
        "    similarity[i] = cos_similarity(word_matrix[i],query_vec)\n",
        "\n",
        "  count = 0\n",
        "\n",
        "  for i in (-1 * similarity).argsort():\n",
        "    if id_to_word[i] == query:\n",
        "      continue\n",
        "\n",
        "    print('{}: {}'.format(id_to_word[i],similarity[i]))\n",
        "\n",
        "    count += 1\n",
        "\n",
        "    if count >= top:\n",
        "      return\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6hJ12xeAbqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ppmi(c,verbose=False,eps=1e-8):\n",
        "  m = np.zeros_like(c,dtype=np.float32)\n",
        "  n = np.sum(c)\n",
        "  s = np.sum(c,axis=0)\n",
        "  total = c.shape[0] * c.shape[1]\n",
        "  cnt = 0\n",
        "\n",
        "  for i in range(c.shape[0]):\n",
        "    for j in range(c.shape[1]):\n",
        "      pmi = np.log2(c[i,j] * n / (s[i] * s[j]) + eps)\n",
        "      m[i,j] = max(0,pmi)\n",
        "\n",
        "      if verbose:\n",
        "        cnt += 1\n",
        "        if cnt % (total // 10) == 0:\n",
        "          print('{:.1f}% done'.format(100 * cnt / total))\n",
        "\n",
        "  return m\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIBDT8yT0uJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = process(text)\n",
        "vocab_size = len(word_to_id)\n",
        "\n",
        "c = create_co_matrix(corpus,vocab_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO9pNW972vP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c0 = c[word_to_id['you']]\n",
        "c1 = c[word_to_id['i']]\n",
        "\n",
        "cos_similarity(c0,c1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgRazlnp3WyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "most_similar('you',word_to_id,id_to_word,c,top=5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2h2WydEIYRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w = ppmi(c,verbose=True)\n",
        "\n",
        "np.set_printoptions(precision=3)\n",
        "print('covariance matrix')\n",
        "print(c)\n",
        "print('-' * 50)\n",
        "print('ppmi')\n",
        "print(w)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaOVITBBtqV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "u, s, v = np.linalg.svd(w)\n",
        "\n",
        "np.set_printoptions(precision=3)\n",
        "print('c:')\n",
        "print(c[0])\n",
        "print('-'*50)\n",
        "print('w:')\n",
        "print(w[0])\n",
        "print('-'*50)\n",
        "print('u:')\n",
        "print(u[0])\n",
        "print('-'*50)\n",
        "print('s:')\n",
        "print(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MyMI9Dl56K3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(1,1)\n",
        "\n",
        "for word, word_id in word_to_id.items():\n",
        "  ax.annotate(word,(u[word_id,0],u[word_id,1]))\n",
        "\n",
        "ax.scatter(u[:,0],u[:,1],alpha=0.5)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEXnO8YH-FMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = os.path.join('/','content','drive','My Drive','Colab Notebooks','Neural Network','RNN')\n",
        "sys.path.append(path)\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/tomsercu/lstm/master/data/'\n",
        "\n",
        "file_name = 'ptb.train.txt'\n",
        "corp_name = 'ptb.train.npy'\n",
        "vocab_name = 'ptb.vocab.pkl'\n",
        "file_path = os.path.join(path,file_name)\n",
        "corp_path = os.path.join(path,corp_name)\n",
        "vocab_path = os.path.join(path,vocab_name)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6O_s4AXH9B-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "urllib.request.urlretrieve(url+file_name,file_path)\n",
        "\n",
        "with open(file_path,'r') as f:\n",
        "  words = f.read().replace('\\n','<eos>').strip()\n",
        "\n",
        "corpus, word_to_id, id_to_word = process(words)\n",
        "\n",
        "np.save(corp_path,corpus)\n",
        "\n",
        "with open(vocab_path,'wb') as f:\n",
        "  pickle.dump((word_to_id,id_to_word),f)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GopFfr0QbbL-",
        "colab_type": "code",
        "outputId": "15e8d942-20f8-455a-c224-a28101143d49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "print('corpus size:', len(corpus))\n",
        "print('corpus[:30]:', corpus[:30])\n",
        "print('-'*50)\n",
        "print('id_to_word[0]:', id_to_word[0])\n",
        "print('id_to_word[1]:', id_to_word[1])\n",
        "print('id_to_word[2]:', id_to_word[2])\n",
        "print('-'*50)\n",
        "print(\"word_to_id['car']:\", word_to_id['car'])\n",
        "print(\"word_to_id['happy']:\", word_to_id['happy'])\n",
        "print(\"word_to_id['lexus']:\", word_to_id['lexus'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus size: 946312\n",
            "corpus[:30]: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29]\n",
            "--------------------------------------------------\n",
            "id_to_word[0]: aer\n",
            "id_to_word[1]: banknote\n",
            "id_to_word[2]: berlitz\n",
            "--------------------------------------------------\n",
            "word_to_id['car']: 3843\n",
            "word_to_id['happy']: 4411\n",
            "word_to_id['lexus']: 7391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9YSU6TV_Jzq",
        "colab_type": "code",
        "outputId": "70aea29e-108f-47a4-cb39-2527c0bfc695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "with open(file_path,'r') as f:\n",
        "  print(f.readline())\n",
        "\n",
        "with open(vocab_path,'rb') as v:\n",
        "  word_to_id, id_to_word = pickle.load(v)\n",
        "\n",
        "corpus = np.load(corp_path)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memotec mlx nahb punts rake regatta rubens sim snack-food ssangyong swapo wachter \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsipSeUxAaj8",
        "colab_type": "code",
        "outputId": "76aa3bcf-e0df-4e51-8d5a-acd059370484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "source": [
        "window_size = 2\n",
        "wordvec_size = 100\n",
        "vocab_size = len(word_to_id)\n",
        "\n",
        "print('counting  co-occurrence ...')\n",
        "cmat = create_co_matrix(corpus,vocab_size,window_size)\n",
        "\n",
        "print('calculating PPMI ...')\n",
        "pmi = ppmi(cmat,verbose=True)\n",
        "\n",
        "print('calculating SVD ...')\n",
        "U, S, V = randomized_svd(pmi,n_components=wordvec_size,\n",
        "                         n_iter=5,random_state=None)\n",
        "\n",
        "print(U.shape)\n",
        "word_vec = U[:,:wordvec_size]\n",
        "\n",
        "querys = ['you', 'year', 'car', 'toyota']\n",
        "for q in querys:\n",
        "  most_similar(q,word_to_id,id_to_word,word_vec,top=5)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "counting  co-occurrence ...\n",
            "calculating PPMI ...\n",
            "10.0% done\n",
            "20.0% done\n",
            "30.0% done\n",
            "40.0% done\n",
            "50.0% done\n",
            "60.0% done\n",
            "70.0% done\n",
            "80.0% done\n",
            "90.0% done\n",
            "100.0% done\n",
            "calculating SVD ...\n",
            "(9944, 100)\n",
            "\n",
            "[query] you\n",
            "i: 0.6367372870445251\n",
            "we: 0.6046673655509949\n",
            "do: 0.5772789716720581\n",
            "'d: 0.5405998229980469\n",
            "'ve: 0.532917857170105\n",
            "\n",
            "[query] year\n",
            "earlier: 0.626132607460022\n",
            "month: 0.6040111780166626\n",
            "last: 0.6022427082061768\n",
            "quarter: 0.5998589396476746\n",
            "months: 0.5788155794143677\n",
            "\n",
            "[query] car\n",
            "auto: 0.68401700258255\n",
            "luxury: 0.5734304189682007\n",
            "vehicle: 0.5165008306503296\n",
            "cars: 0.49752214550971985\n",
            "lexus: 0.4760116636753082\n",
            "\n",
            "[query] toyota\n",
            "motor: 0.6689599752426147\n",
            "motors: 0.6526650786399841\n",
            "nissan: 0.6430892944335938\n",
            "honda: 0.6414303183555603\n",
            "lexus: 0.52358478307724\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}